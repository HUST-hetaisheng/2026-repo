%%
%% This is file `mcmthesis-demo.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% mcmthesis.dtx  (with options: `demo')
%% !Mode:: "TeX:UTF-8"
%% -----------------------------------
%% This is a generated file.
%% 
%% Copyright (C) 2010 -- 2015 by latexstudio
%%       2014 -- 2019 by Liam Huang
%%       2019 -- present by latexstudio.net
%% 
%% License: The LaTeX Project Public License 1.3c
%% 
%% The Current Maintainer of this work is latexstudio.net.
%% 
\documentclass{mcmthesis}
 %\documentclass[CTeX = true]{mcmthesis}  % 当使用 CTeX 套装时请注释上一行使用该行的设置
\mcmsetup{tstyle=\color{red}\bfseries,%修改题号，队号的颜色和加粗显示，黑色可以修改为 black
        tcn = 2607256, problem = C, %修改队号，参赛题号
        sheet = true, titleinsheet = false, keywordsinsheet = true,%修改sheet显示信息
        titlepage = false, abstract = true}

  %四款字体可以选择
  %\usepackage{times}
  \usepackage{newtxtext,newtxmath} %CTeX 无此字体，可用 txfonts 替代，请使用新版 TeXLive.
  %\usepackage{palatino}
  %\usepackage{txfonts}
  \usepackage{colortbl}  %彩色表格需要加载的宏包
\usepackage{xcolor}
\usepackage{array}
\usepackage{cite} % 用于导入图片
\usepackage{pifont}
\usepackage{indentfirst}  %首行缩进，注释掉，首行就不再缩进。
\usepackage{lipsum}
\usepackage{algorithm}
\usepackage{algpseudocode}
\title{The \LaTeX{} Template for MCM Version \MCMversion}
\author{\small \href{https://www.latexstudio.net/}
  {\includegraphics[width=7cm]{mcmthesis-logo}}}
\date{\today}
\begin{document}
\begin{abstract}
\par In the show \textit{Dancing with the Stars}, judges’ scores and fan votes determine competition outcomes together, directly influencing fairness as different scoring regulations lead to different results. Our study establishes a systematic analytical framework to estimate confidential fan votes.By using the model,we can evaluate the impact of voting rules, quantify the effects of contestant traits and partner characteristics,and ultimately proposing  fairer and more effective scoring rules.

\textbf{For Task 1} we developed an \textbf{entropy‑inertia regularized inverse optimization model} to estimate latent weekly fan vote shares. The model can be divided to three historical scoring regimes%,including the \textbf{Rank method} (Seasons 1–2), the \textbf{Percent method} (Seasons 3–27), and the \textbf{Judges’ Choice method} (Seasons 28–34)
. By maximizing entropy to avoid unwarranted assumptions and enforcing temporal smoothness to reflect fan‑base stability, the model successfully reconstructs elimination outcomes with a high consistency probability of \textbf{0.93}. %The most reliable inference occurs under the Percent regime. 
Uncertainty measures are quantified via ensemble inference, revealing regime‑dependent confidence patterns.

\textbf{For Task 2} we conducted \textbf{counterfactual simulations} to compare \textbf{the Rank‑Sum method} and \textbf{the Percentage‑Sum method}. The simulations are totally different in \textbf{93 weeks} across all seasons.The Percentage method protects the contestant with higher fan support in \textbf{60.2\% }of instances, acting as a \textbf{“fan‑power amplifier”} while the two‑stage elimination framework \textbf{(Judges’ Choice)} significantly reduces the survival probability of low‑skill but high‑popularity contestants, serving as an effective correction mechanism.

\textbf{For Task 3} we employed a \textbf{multi‑level regression framework} and a \textbf{Linear Mixed‑Effects Model} to quantify the effects of judges and parterns. Static‑trait analysis shows that judges’ scores are negatively correlated with contestant's \textbf{age}, and \textbf{social media celebrities} are the most likely to stand out. Dynamic weekly analysis confirms \textbf{social‑media popularity} predicts fan vote share. The Mixed-Effects model reveals that good \textbf{dancing partners} do boost the final results with better judge scores. 

\textbf{For Task 4}, we developed a \textbf{Weekly Dynamic Weighting System} framed as an \textbf{optimal control problem} to optimize the judge‑score weight ($\lambda_t$). The objective maximizes a composite metric balancing \textbf{Commercial Value (30\%), Fairness (40\%), Fan Satisfaction (20\%), and Celebrity Benefit (10\%)}. Using \textbf{Differential Evolution}, dynamic control outperformed static strategies, achieving a \textbf{43.5\% improvement} in \textbf{Season~25}. The optimal \textbf{``N‑Shape'' trajectory} strategically phases judge influence---accumulating traffic, enforcing a mid‑season professional firewall, boosting engagement, and ensuring a qualified winner---raising the show's overall benefit by \textbf{22.9\%} through real‑time fairness‑appeal balance.

\textbf{Synthesizing all findings}, we recommend adopting the \textbf{Percentage Aggregation Method} as the foundational scoring rule to maximize viewer engagement, while retaining the \textbf{Judges’ Selection Privilege (Bottom‑Two mechanism)} to uphold technical standards and ensure competitive fairness. This hybrid system allows popular appeal to shape competition while granting judges a necessary corrective veto.

\begin{keywords}
Vote Estimation;Inverse Optimization;Mixed‑Effects Model;Scoring Fairness
\end{keywords}
\end{abstract}
\maketitle
%% Generate the Table of Contents, if it's needed.
\tableofcontents
\newpage
%%
%% Generate the Memorandum, if it's needed.
%% \memoto{\LaTeX{}studio}
%% \memofrom{Liam Huang}
%% \memosubject{Happy \TeX{}ing!}
%% \memodate{\today}
%% \memologo{\LARGE I'm pretending to be a LOGO!}
%% \begin{memo}[Memorandum]
%%   \lipsum[1-3]
%% \end{memo}
%%
\section{Introduction}
\subsection{Background}

DWTS (Dancing with the Stars) is a popular television competition where celebrity contestants are paired with professional dancers to compete in weekly dance performances. Elimination and advancement are determined by combining judges’ scores and audience votes.The judges assess technical proficiency, which can be subjective, while fan votes are influenced by factors such as celebrity popularity and charisma\cite{r4}. As a result, the competition's outcomes have often sparked discussions and controversies, despite the show's attempts to improve the integration of these two elements. In recent years, with increasing audience concerns about fairness in competitive variety shows, DWTS faces a critical need for a fair, impartial, and effective scoring system. This system must ensure both the program's entertainment value and the confidentiality of fan votes, securing a balance between professionalism and popularity. This is essential for DWTS to maintain its viewership and grow its brand in future seasons.
% \begin{figure}[H]
%     \centering
%     \includegraphics[width=0.35\linewidth]{figures/dwtc背景图.png}
%     \caption{Dancing with the Stars poster}
%     \label{fig:placeholder}
% \end{figure}

\begin{figure}[H]
    \centering
    \begin{minipage}{0.37\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figures/dwtc背景图.png}
    \end{minipage}
    \hspace{0.05\linewidth}
    \begin{minipage}{0.37\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figures/dwtc问题综述图.png}
    \end{minipage}
    \textbf{\caption{Dancing with the Stars}}
    \label{fig:dwtc_overview}
\end{figure}



% \subsection{Restatement of the Problem}

% Given the background information and available data, this study addresses the following tasks.

% \textbf{Task 1: Fan Vote Estimation.}
% \textbf{1.1}\quad Construct a model to estimate weekly fan votes using judges’ scores, elimination outcomes, and contestant data.  
% \textbf{1.2}\quad Evaluate the consistency of the estimates by testing whether they reproduce the observed weekly eliminations.  
% \textbf{1.3}\quad Quantify the uncertainty of the estimated fan votes and examine whether it varies across contestants or weeks.

% \textbf{Task 2: Comparison of Vote Combination and Elimination Rules.}
% \textbf{2.1}\quad Compare the rank-based and percentage-based vote combination methods across seasons and analyze potential biases.  
% \textbf{2.2}\quad Evaluate the impact of alternative elimination procedures, including judges selecting from the bottom two contestants.  
% \textbf{2.3}\quad Recommend an appropriate combination and elimination approach for future seasons with justification.

% \textbf{Task 3: Impact of Contestant and Partner Characteristics.}
% \textbf{3.1}\quad Assess the influence of professional dancer traits and celebrity characteristics on overall performance and final results.  
% \textbf{3.2}\quad Compare the effects of these factors on judges’ scores versus fan votes.

% \textbf{Task 4: Alternative Scoring System.}
% \textbf{4.1}\quad Design an alternative method for combining judges’ scores and fan votes.  
% \textbf{4.2}\quad Demonstrate that the proposed system is more fair or otherwise improves the competition.
\subsection{Restatement of the Problem}

Given the background information and available data, this study addresses the following tasks.

\textbf{Task 1: Fan Vote Estimation.}\quad
A mathematical model is developed to estimate weekly fan vote totals for each contestant using judges’ scores, elimination outcomes, and contestant data. The model’s consistency is evaluated by its ability to reproduce observed weekly eliminations, and the uncertainty of the estimated fan votes is quantified and analyzed across contestants and weeks.

\textbf{Task 2: Comparison of Vote Combination and Elimination Rules.}\quad
Using the estimated fan votes, the rank-based and percentage-based methods for combining judges’ scores and fan votes are compared across seasons. The effects of alternative elimination procedures, including judges selecting from the bottom two contestants, are also evaluated, leading to a justified recommendation for future seasons.

\textbf{Task 3: Impact of Contestant and Partner Characteristics.}\quad
The impacts of professional dancer traits and celebrity characteristics on competition outcomes are analyzed, with a comparison of their influences on judges’ scores and fan votes.

\textbf{Task 4: Alternative Scoring System.}
An alternative scoring system combining \quad
judges’ scores and fan votes is proposed and evaluated to determine whether it improves fairness or other aspects of the competition.


\section{Preparations for Modeling}

\subsection{Model Assumptions}

\textbf{Assumption 1 (Vote Share Modeling):}
Fan votes are modeled as relative vote shares rather than absolute counts. For each week, all contestants’ vote shares are nonnegative and sum to one.

\textbf{Assumption 2 (Temporal Smoothness):}
For contestants remaining in the competition, fan vote shares change smoothly between consecutive weeks.

\textbf{Assumption 3 (Maximum Entropy):}
In the absence of restrictive information, fan vote distributions are assumed to be as uniform as possible.

\textbf{Assumption 4 (Judges’ Save Bias):}
When judges choose between the bottom two contestants, they are more likely to save the contestant with the higher judges’ score, but the decision is not deterministic.

\textbf{Assumption 5 (Stability to Perturbations):}
Small perturbations in judges’ scores produce bounded changes in the estimated fan vote shares.

\textbf{Assumption 6 (Independent Perturbations):}
Judges’ score perturbations are assumed to be independent across contestants and weeks.


\subsection{Notations}
\label{sec:notations}

We use the following notation throughout the paper:

% \begin{table}[H]
% \centering
% \caption{Key Notations and Symbols}
% \begin{tabular}{cl}
% \toprule
% \textbf{Symbol} & \textbf{Definition} \\
% \midrule
% $i$ & Contestant index \\
% $t$ & Week index (1 to $T$) \\
% $s$ & Season index (1 to 34) \\
% $J_{i,t}$ & Total judges' score for contestant $i$ in week $t$ \\
% $j_{i,t}$ & Judges' score share: $j_{i,t} = J_{i,t} / \sum_{k\in A_t} J_{k,t}$ \\
% $f_{i,t}$ & Fan vote share for contestant $i$ in week $t$ (estimated) \\
% $V_{i,t}$ & Absolute fan vote count: $V_{i,t} = T_t \cdot f_{i,t}$ \\
% $T_t$ & Total votes cast in week $t$ (set to $10^7$ for presentation) \\
% $c_{i,t}$ & Combined score: $c_{i,t} = j_{i,t} + f_{i,t}$ (Percent regime) \\
% $r^J_{i,t}$ & Judges' rank for contestant $i$ in week $t$ (Rank regime) \\
% $r^F_{i,t}$ & Fan vote rank for contestant $i$ in week $t$ (Rank regime) \\
% $A_t$ & Active contestant set in week $t$: $A_t = \{i : J_{i,t} > 0\}$ \\
% $E_t$ & Eliminated contestant set in week $t$ (vote-determined) \\
% $S_t$ & Safe contestant set in week $t$: $S_t = A_t \setminus E_t$ \\
% $\delta_t$ & Slack variable for week $t$ (relaxes hard constraints) \\
% $\alpha, \beta, \gamma$ & Regularization hyperparameters \\
% $M$ & Large penalty coefficient for slack minimization \\
% $K$ & Number of ensemble runs for uncertainty quantification \\
% \bottomrule
% \end{tabular}
% \label{tab:notations}
% \end{table}


\begin{table}[H]
\centering
\caption{Key Notations and Symbols}
\begin{tabular}{cl}
\toprule
\textbf{Symbol} & \textbf{Definition} \\
$j_{i,t}$ & Judges' score share: $j_{i,t} = J_{i,t} / \sum_{k\in A_t} J_{k,t}$ \\
$f_{i,t}$ & Fan vote share for contestant $i$ in week $t$ (estimated) \\
$c_{i,t}$ & Combined score: $c_{i,t} = j_{i,t} + f_{i,t}$ \\
$A_t$ & Active contestant set in week $t$ \\
$E_t$ & Eliminated contestant set in week $t$ \\
$S_t$ & Safe contestant set: $S_t = A_t \setminus E_t$ \\
$Y_i$ & Outcome variable (Judge Score / Fan Vote / Placement) \\
$Y_{it}$ & Outcome for contestant $i$ in week $t$ (weekly model) \\
$u_j$ & Random effect for professional dancer $j$ \\
$\delta_t$ & Slack variable for week $t$ \\
$\alpha$ & Regularization hyperparameter \\
$K$ & Number of ensemble runs \\
\bottomrule
\end{tabular}
\label{tab:notations}
\end{table}


% \begin{itemize}
% \item \textbf{Missing and placeholder values.}  
% In the original dataset, zero values indicate either judge absences or post-elimination weeks. A contestant-week is treated as \emph{active} if at least one judge score is positive. For each active observation, the total judges' score $J_{i,t}$ is computed as the sum of all non-zero individual scores. Elimination outcomes are extracted from the \texttt{results} column. Contestants labeled as ``Withdrew'' are flagged separately, as their exits are not vote-determined and thus impose no constraints on fan vote estimation.

% \item \textbf{Rule regime classification.}  
% Each season is classified according to the competition rules in effect \cite{WikiDWTS}: \emph{Rank} (Seasons~1--2), where judges' and fan rankings are combined; \emph{Percent} (Seasons~3--27), where normalized score shares are added; and \emph{Bottom2} (Seasons~28--34), where judges select which contestant to save from the bottom two. This classification determines the form of elimination constraints used in the inverse model.

% \item \textbf{Elimination pattern annotation.}  
% Each week is labeled by its elimination structure, including single elimination, double elimination, no elimination (results shows), and finals. For finals weeks, the \texttt{placement} column is used to determine the final ranking among remaining contestants.

% \item \textbf{Data validation.}  
% We verify that eliminations are monotonic (no contestant reappears after elimination), that finals rankings are consistent with the final active set, and that all judge scores lie within the valid 1--10 range.
% \end{itemize}


\subsection{Data Preprocessing}
\label{sec:data_processing}

The raw dataset covers 34 seasons and includes 421 celebrity--partner pairs with weekly judges' scores and elimination outcomes. Several preprocessing steps are applied to prepare the data for modeling.

The provided dataset is complete and well-structured. To facilitate computation, we performed systematic cleaning: cells with judges' scores marked as ``N/A'' are converted to 0, and a contestant-week is considered \textbf{active} if at least one judge score is positive. For each active observation, the total judges' score $J_{i,t}$ is computed as the sum of all non-zero individual scores. Binary indicators are created for variables such as \textbf{``born in the US''}. For eliminated contestants, we record the \textbf{week of elimination}; for contestants who withdrew mid-competition, we flag them separately since their exits are not vote-determined. Professional dance partners were assigned with unique identifiers.

\textbf{Rule regime classification} is essential given the show's evolving format. Each season is labeled according to the competition rules in effect: Seasons 1--2 use the \textbf{``Rank''} method (judges' and fan rankings are summed), Seasons 3--27 use the \textbf{``Percent''} method (normalized score shares are added), and Seasons 28--34 use the \textbf{``Bottom-2''} method (judges select which contestant to eliminate from the bottom two). This classification determines the form of elimination constraints used in the inverse model.

To enrich the dataset for Task 3, we collected supplementary data via \textbf{web scraping}: weekly \textbf{social media follower counts} across major platforms (Twitter, Instagram, Facebook, YouTube), Google Trends \textbf{search frequency} during the competition period, as well as contestants' \textbf{BMI} and \textbf{prior dance experience} metrics from public sources.

After preprocessing, the cleaned dataset contains \textbf{2,777 valid contestant-week observations} with complete judges' scores and unambiguous elimination status.


\section{The Entropy-Inertia Regularized Inverse Optimization Model}

\subsection{Rationale and Overall Architecture}
The central challenge of this problem is that fan votes ($\mathbf{v}_t$) are unobserved latent variables, while only the weekly elimination results ($E_{obs}$) are known. This constitutes an \textbf{ill-posed inverse problem} with incomplete information: a single elimination event determines the lowest-ranked contestant but leaves the relative ordering of the survivors underdetermined\cite{r2}. 

To reconstruct the fan votes robustly, a valid model must: (i) \textbf{Respect Historical Regimes} by adapting to the specific aggregation rules (Rank vs. Percent) that evolved over 34 seasons; (ii) \textbf{ Account for irregularities} such as weeks with no elimination, double eliminations, and mid-competition withdrawals; and (iii) \textbf{Avoid Bias}. Unlike simplistic approaches that impose a correlation between fan votes and judge scores, we adopt an \textbf{unbiased} approach that only assumes fundamental statistical properties: entropy and temporal inertia.

Therefore, we propose a \textbf{Regime-Specific, Week-Type Aware Inverse Optimization Framework}. We classify the problem into three distinct mathematical sub-models 

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{rules_chart.png}
    \caption{Regime  Timeline}
    \label{fig:rules_chart}
\end{figure}

% corresponding to the show's eras: \textit{The Rank Regime} (S1--2), \textit{The Percent Regime} (S3--27), and \textit{The Judges' Choice Regime} (S28--34).

\subsection{Week-Type Identification}
The transformation from observed elimination results to latent fan votes represents an ill-posed inverse problem. To restrict the feasible solution space effectively, we must adapt our optimization constraints dynamically. Different competitive scenarios imply varying degrees of logical restrictiveness. Accordingly, we identify five distinct week archetypes to tailor the constraint set $\Omega_w$.

In standard \textbf{single-elimination} weeks ($|E_w|=1$), a strict inequality separates the eliminated contestant from all survivors, while in \textbf{multiple-elimination} weeks ($|E_w|>1$), all eliminated contestants must score lower than any remaining contestant. In weeks with \textbf{no elimination} ($E_w=\varnothing$), no hard constraints are imposed, and vote evolution is guided solely by temporal smoothness. Withdrawals are treated as non-informative events for the withdrawn contestant, with constraints applied only to the remaining pool if a vote-based elimination still occurs. In \textbf{finals weeks}, the observed final placements ${p_1, p_2, \dots}$ induce a total or partial ordering, yielding the strongest set of constraints.
% =================================================================================
% MODEL 1: PERCENT REGIME (The Convex Optimization Core)
% =================================================================================
\subsection{The Percent Regime Model (Seasons 3--27)}
\label{sub:percent_model}

\subsubsection{Mathematical Formulation}
In these seasons, the judge score share $j_{i,w}$ and fan vote share $f_{i,w}$ are additive. The total combined score $S_{i,w}$ is defined as $S_{i,w} = j_{i,w} + f_{i,w}$. Since the variables are continuous and the constraints are linear, this yields a \textbf{Convex Optimization Problem}\cite{r5}.

\subsubsection{The Unbiased Objective Function (MaxEnt + Inertia)}
We explicitly reject the inclusion of a "Judge Consensus" term to avoid confirmation bias. Instead, we minimize a composite objective function $\mathcal{L}(f_w)$ grounded in Information Theory:

\begin{equation}
    \min_{f_w} \quad \mathcal{L}(f_w) = \underbrace{\sum_{i} f_{i,w} \ln f_{i,w}}_{\text{Negative Entropy}} + \lambda \underbrace{\sum_{i} f_{i,w} \ln \left( \frac{f_{i,w}}{f_{i,w-1}} \right)}_{\text{Temporal Inertia (KL Divergence)}} + \rho \mathcal{L}_{place}
\end{equation}

The first term, \textbf{Negative Entropy}, ensures the distribution is as uniform as possible unless the data (elimination constraints) forces otherwise. This prevents the model from assuming arbitrary popularity spikes. The second term, \textbf{Temporal Inertia}, utilizes Kullback-Leibler divergence to penalize deviation from the previous week's posterior, reflecting the sociological "stickiness" of fan bases.

Finally, if partial placement data is available (e.g., "Contestant A was 3rd, B was 4th" among eliminated), we add a \textbf{Hinge Loss} soft penalty $\mathcal{L}_{place} = \sum_{(a,b) \in \mathcal{P}_w} \max\left(0, S_{b,w} - S_{a,w} + \epsilon \right)$, where $\mathcal{P}_w$ is the set of known pairs where $a$ ranked better than $b$.

\subsubsection{Hard Constraints}
The feasible region is defined by the elimination event. Let $E_w$ be the set of eliminated contestants and $S_{safe}$ be the set of survivors. The constraint $S_{e,w} \le S_{s,w}$ ($\forall e \in E_w, \forall s \in S_{safe}$) forms a convex polytope. We solve this using the \textbf{Sequential Least Squares Programming (SLSQP)} algorithm, guaranteeing a global optimum.

% =================================================================================
% MODEL 2: RANK REGIME (The Discrete Combinatorial Core)
% =================================================================================
\subsection{The Rank Regime Model (Seasons 1--2)}

\subsubsection{The Discrete Challenge}
In rank-based seasons, inputs are ordinal integers $r \in \{1, \dots, N\}$. The combined score is the sum of ranks $R_{total, i} = r^J_{i} + r^F_{i}$, where $r^F$ is a permutation vector. The inverse problem becomes a \textbf{Combinatorial Optimization} task (NP-Hard nature), prohibiting gradient-based methods.

\subsubsection{Greedy Heuristic Search Algorithm}
Instead of brute-force enumeration ($N!$ complexity), we employ a \textbf{Stochastic Greedy Swapping Heuristic}. The algorithm proceeds in three steps:
\textbf{First}, it initializes with a fan rank permutation $r^F$ correlated with judge ranks to ensure a valid starting point.
\textbf{Second}, it validates the elimination rule: $\max_{e \in E_w} (R_{total, e}) \ge \max_{s \in S_{safe}} (R_{total, s})$.
\textbf{Third}, if the constraint is violated (i.e., the actual eliminated star has a "better" score than a survivor), the algorithm performs minimal swaps between the survivor and the eliminated star until the condition holds, prioritizing permutations that minimize the Kendall-Tau distance from the previous week.

\subsubsection{Rank-to-Share Mapping (Gibbs Distribution)}
To compare these results with Percent seasons, we map the inferred discrete ranks $r^F_i$ to continuous shares $f_i$ using a Softmax distribution:
\begin{equation}
    f_{i} = \frac{\exp(-\gamma \cdot (r^F_{i} - 1))}{\sum_k \exp(-\gamma \cdot (r^F_{k} - 1))}
\end{equation}
where $\gamma$ is solved using data from the third season, then back-substituted into the current stage's problem solution.

% =================================================================================
% MODEL 3: JUDGES' SAVE REGIME (The Probabilistic Extension)
% =================================================================================
\subsection{The Judges' Choice Model (Seasons 28--34)}

Starting from Season 28, the competition introduced a two-stage elimination procedure: combined judge and fan votes first determine a ``Bottom Two'' pool, then judges vote to save one contestant. This mechanism requires explicit probabilistic modeling of the judges' decision.

\subsubsection{Two-Stage Elimination Framework}

The latent variable to infer is the fan vote ranking $\mathbf{r}^F_w = (r^F_{1,w}, \ldots, r^F_{N,w})$, a permutation of $\{1, \ldots, N\}$ where $r^F_i = 1$ indicates the highest fan support. The combined rank $R_{i,w} = r^J_{i,w} + r^F_{i,w}$ determines overall standing, with higher values indicating worse performance. The Bottom-Two set $\mathcal{B}(\mathbf{r}^F_w) = \{a, b\}$ consists of the two contestants with the highest combined ranks. Given this set, the probability that judges eliminate contestant $a$ follows a logistic choice model:
\begin{equation}
    P(\text{Elim } a \mid a, b \in \mathcal{B}) = \frac{1}{1 + \exp\left(\beta(J_a - J_b)\right)}
    \label{eq:judge_choice}
\end{equation}
where $\beta > 0$ quantifies the judges' tendency to save higher-scored contestants. When $\beta \to \infty$, the lower-scored contestant is deterministically eliminated; when $\beta = 0$, the choice is random.

\subsubsection{Optimal Ranking Inference}

The inference task is to find the fan ranking $\mathbf{r}^{F*}_w$ that maximizes the likelihood of the observed elimination outcome. Let $e$ denote the actually eliminated contestant. The optimization problem is:
\begin{equation}
    \mathbf{r}^{F*}_w = \arg\max_{\mathbf{r}^F \in \mathcal{S}_N} \; P(\text{Elim } e \mid \mathcal{B}(\mathbf{r}^F)) \quad \text{s.t.} \quad e \in \mathcal{B}(\mathbf{r}^F)
\end{equation}
where $\mathcal{S}_N$ is the set of all permutations. To maximize $P(\text{Elim } e)$, the other Bottom-Two member $b$ should satisfy $b^* = \arg\max_{b \neq e} J_b$, i.e., the highest-scored contestant who can feasibly join $e$ in the danger zone. This choice minimizes $(J_e - J_b)$, thereby maximizing the elimination probability. Consequently, the fan ranking must satisfy, for all survivors $i \notin \{e, b^*\}$:
\begin{equation}
    r^F_e \geq r^F_i + (r^J_i - r^J_e), \quad r^F_{b^*} \geq r^F_i + (r^J_i - r^J_{b^*})
    \label{eq:rank_constraint}
\end{equation}
These inequalities impose lower bounds on $r^F_e$ and $r^F_{b^*}$, forcing them to occupy sufficiently poor fan-vote positions to form the Bottom-Two.

\subsubsection{Algorithmic Implementation and Vote Share Conversion}

Since the search space $\mathcal{S}_N$ is factorial, we employ a greedy swapping heuristic. Starting from a prior ranking (previous week's result or judge-correlated ranks), the algorithm iteratively swaps positions to satisfy the constraints in Eq.~\eqref{eq:rank_constraint} while maximizing the objective. Once the optimal ranking $\mathbf{r}^{F*}_w$ is obtained, it is converted to continuous vote shares via Gibbs-Softmax transformation:
\begin{equation}
    f_{i,w} = \frac{\exp\left(-\gamma (r^{F*}_{i,w} - 1)\right)}{\sum_{k=1}^N \exp\left(-\gamma (r^{F*}_{k,w} - 1)\right)}
\end{equation}
where $\gamma > 0$ controls the steepness of the decay. To quantify uncertainty, we perform ensemble inference by perturbing judge scores with Gaussian noise and repeating the optimization, yielding a posterior distribution over $f_{i,w}$.

In conclusion, our model demonstrates strong empirical validity: it correctly recovers elimination outcomes with high probability (overall $\bar{P}_{\text{cons}} = 0.93$), while uncertainty quantification reveals interpretable regime-dependent patterns that align with the theoretical information content of each voting mechanism\cite{r6}. The Percent regime provides the most reliable inference, while the judges' save mechanism in recent seasons introduces irreducible ambiguity that is faithfully captured by our probabilistic framework.
\section{Rank VS Percent Method with predicted data} 
\subsection{Influence of Voting Methods on Final Outcomes}

Estimated fan vote shares are combined with original judges’ scores to simulate eliminations under two counterfactual rules: the Rank method (rank-sum) and the Percentage method (score-share sum). As shown in Table~\ref{tab:rank_pct_metrics}, the two methods agree in 72.2\% of weeks but differ in 93 cases. In weeks of disagreement, a positive $\Delta_{fan}$ indicates that the Rank method eliminates a contestant with higher fan support, implying that the Percentage method is more fan-favorable.

Regression results in Figure~\ref{fig:safety_margin} show a positive association ($\beta = 2.40$), indicating that a 10-percentage-point increase in fan vote share improves a contestant’s relative standing by approximately 0.24 ranks under the Percentage Rule compared to the Rank Rule. Although the $R^2$ is modest, the relationship is statistically significant.

This pattern is reinforced by elimination outcomes. Among the 93 divergent weeks, the Percentage Rule protected the higher–fan-support contestant in 56 cases (60.2\%), compared to 37 cases (39.8\%) under the Rank Rule, yielding a ratio of 1.51:1. Overall, the Percentage Rule places greater weight on audience preferences, whereas the Rank Rule produces more balanced outcomes between judges’ scores and fan votes.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.8\linewidth]{figures/safety_margin_correlation_beautiful.png}
\caption{Fan vs. judge agreement structure (left: rank comparison; right: share comparison).}
\label{fig:safety_margin}
\end{figure}
\begin{table}[H]
% 移除 \centering，使用 \textwidth 占满全宽
\setlength{\tabcolsep}{0pt} % 将默认列间距设为0，由 extracolsep 自动填充
\caption{Rank vs. Percentage simulation metrics (overall and by regime).}
\label{tab:rank_pct_metrics}
\renewcommand{\arraystretch}{1.2} % 稍微增加行高，防止拥挤
% 使用 tabular* 并设置宽度为 \textwidth
% @{\extracolsep{\fill}} 会自动计算列间距以填满整行
\begin{tabular*}{\textwidth}{@{\extracolsep{\fill}} l r r r r r @{}}
\toprule
\multicolumn{6}{l}{\textbf{Overall (All Seasons)}}\\
\midrule
\textbf{Metric} & \textbf{Value} & \multicolumn{4}{c}{} \\ % 使用 multicolumn 填补剩余空白
\midrule
Total weeks analyzed & 335 & \multicolumn{4}{c}{} \\
Method agreement rate & 0.722 & \multicolumn{4}{c}{} \\

Disagree weeks & 93 & \multicolumn{4}{c}{} \\
Fan-favored by Rank (count) & 37 & \multicolumn{4}{c}{} \\
Fan-favored by Percentage (count) & 56 & \multicolumn{4}{c}{} \\
Avg $\Delta_{fan}$ (disagree weeks) & 0.0086 & \multicolumn{4}{c}{} \\
Avg eliminated fan share (Rank) & 0.1170 & \multicolumn{4}{c}{} \\
Avg eliminated fan share (Pct) & 0.1146 & \multicolumn{4}{c}{} \\
\midrule
\multicolumn{6}{l}{\textbf{By Regime}}\\
\midrule
\textbf{Regime} & \textbf{Weeks} & \textbf{Agreement} & \textbf{Avg $\Delta_{fan}$} & \textbf{Fan$\to$Rank} & \textbf{Fan$\to$Pct} \\
\midrule
Bottom-2 Era (S28--34) & 73  & 0.808 & 0.0384 & 2  & 12 \\
Percent Era (S3--27)   & 248 & 0.694 & 0.0006 & 35 & 41 \\
Rank Era (S1--2)       & 14  & 0.786 & 0.0722 & 0  & 3  \\
\bottomrule
\end{tabular*}

\par\vspace{0.5em}
{\footnotesize 
\noindent \textbf{Note:} $\Delta_{fan}>0$ implies the Rank method eliminates a contestant with a higher fan share compared to the Percentage method. Columns \textbf{Fan$\to$Rank} and \textbf{Fan$\to$Pct} denote the count of weeks where that specific method was more favorable to the popular vote.}
\end{table}
\subsection{Mathematical Framework of Counterfactual Voting Rules}

The core of our comparative analysis lies in the mathematical formalization of the two predominant aggregation methods. In the Rank-Sum Method, used in the earliest seasons, the standing of contestant $i$ in week $w$ is determined by the discrete summation of ordinal ranks, expressed as $T^R_{i,w} = R^J_{i,w} + R^F_{i,w}$, where $R^J$ and $R^F$ represent judge and fan rank points respectively. Conversely, the Percentage Method, or Score-Share Sum Method, preserves the magnitude of competitive gaps by summing technical and popular shares:
\begin{equation}
    T^P_{i,w} = \frac{Score_{i,w}}{\sum_{k=1}^{n} Score_{k,w}} + FanShare_{i,w}
\end{equation}
To allow for a standardized comparison across seasons with varying contestant counts and scoring densities, we transform these raw aggregates into a Standardized Safety Margin (SSM), denoted as $Z_{i,w} = (T_{i,w} - \mu_w) / \sigma_w$, where $\mu_w$ and $\sigma_w$ characterize the weekly distribution of total scores. This transformation ensures that $Z_{i,w}$ captures the relative competitive advantage of a contestant, independent of the underlying rule's scale.

\subsubsection{Probabilistic Survival Dynamics and Mapping}

Recognizing that eliminations in a high-stakes competition are rarely deterministic, we depart from a binary 0/1 outcome by introducing a buffer space modeled through a logistic survival function. The weekly survival probability $p_{i,w}$ is defined as follows:
\begin{equation}
    p_{i,w} = \begin{cases} 
    1.0, & \text{if no elimination occurs in week } w \\ 
    \frac{1}{1 + e^{-(\alpha + \beta_s Z_{i,w})}}
, & \text{if elimination occurs} 
    \end{cases}
\end{equation}
We set the threshold offset $\alpha = 2.2$ to reflect a baseline survival expectation of approximately 90\% for an average performer ($Z=0$), while the sensitivity $\beta_s = 1.5$ modulates the penalty for poor technical scores. The cumulative survival function, $P_{cum}(i, W) = \prod_{w=1}^{W} p_{i,w}$, thus serves as a longitudinal measure of a contestant’s resilience against the risk of elimination over the course of a season.

\subsubsection{The Two-Stage Filter: Integration of Judges' Choice}

To investigate the institutional response to popular dominance, we incorporate the two-stage elimination framework introduced in later seasons. In this mechanism, the aggregated votes first determine a Bottom-Two set $\mathcal{B} = \{a, b\}$, after which the judges exercise a final decision. We model the professional intervention probability using the logistic choice model established in earlier sections:
\begin{equation}
    P(\text{Save } i \mid i, j \in \mathcal{B}) = \frac{\exp\left(\gamma(J_i - J_j)\right)}{1 + \exp\left(\gamma(J_i - J_j)\right)}
\end{equation}
where $J_i$ and $J_j$ are raw technical scores and $\gamma$ quantifies the judges' professional bias. This dual-layer survival structure effectively introduces a "technical barrier" that limits the progression of high-popularity but low-skill contestants, essentially capping their cumulative survival probability regardless of fan support.

\subsubsection{Empirical Analysis of Divergent Contestants}

Our simulation highlights eight prominent "divergent" contestants whose trajectories differ significantly under the two rules. As illustrated in Figure~\ref{fig:survival_curves}, the Percentage Rule acts as a significant "fan-power amplifier." For contestants like Bobby Bones, Iman Shumpert, and Nelly, the Percentage Rule allows massive popular margins to effectively bridge large technical gaps, leading to substantial gains in cumulative survival. Conversely, under the Rank-Sum Rule, the technical disadvantage of performers such as Jerry Rice, Bristol Palin, and Billy Ray Cyrus becomes far more difficult to overcome due to the ceiling on rank points.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{probabilistic_survival_comparison.png}
    \caption{Survival Curve:Rank VS Percent}
    \label{fig:survival_curves}
\end{figure}

\begin{table}[htbp]
\centering
\caption{Comparative Estimated Placements and Survival Gains}
\label{tab:placement_shifts}
\rowcolors{2}{gray!10}{white}
\begin{tabular}{lcccc}
\hline
\rowcolor{blue!20} Contestant (Season) & Actual Rank & Rank Rule Est. & Percent Rule Est. & Survival Advantage \\
\midrule
Bobby Bones (S27) & 1 & 11 & 5 & Percentage \\
Iman Shumpert (S30) & 1 & 10 & 3 & Percentage \\
Nelly (S29) & 3 & 12 & 9 & Percentage \\
Alyson Hannigan (S32) & 5 & 6 & 4 & Percentage \\
Lauren Alaina (S28) & 4 & 5 & 4 & Percentage \\
Jerry Rice (S2) & 2 & 7 & 7 & Rank \\
Bristol Palin (S11) & 3 & 8 & 7 & Percentage \\
Billy Ray Cyrus (S4) & 5 & 9 & 8 & Percentage \\
\bottomrule
\end{tabular}
\end{table}

The empirical results in Table~\ref{tab:placement_shifts} further validate that the introduction of the Judges' Choice mechanism significantly curtails the advancement of these divergent performers. For instance, while Cody Rigsby and Stephen Nedoroscik maintained high survival under popular vote rules, our model predicts that their probability of victory would drop by over 60\% if they were forced into a Bottom-Two decision against technical front-runners. Ultimately, the transition from the Rank Rule to the Percentage Rule favors popular appeal, but the addition of the Judges' Choice serves as a necessary professional correction that aligns final results more closely with ballroom expertise.
\subsubsection{Impacts of judge's choice rule}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{Code_Generated_Image (1).png}
    \caption{Judge's Choice impact}
    \label{fig:judge}
\end{figure}
After introducing judges' intervention in the elimination round, contestants with lower initial judge scores—such as Bobby Bones and Iman Shumpert—faced significantly reduced survival rates. As shown in the Figure~ref{fig:judge}, the survival rate under the percent scoring method dropped substantially (to less than one-third of the original rate) compared to the rank scoring method following the judges' selection. This effectively curbed the “fan frenzy effect.” It is widely acknowledged that judges' scores are more subjective than audience votes and better reflect contestants' true abilities. This reduces the likelihood of upsets driven solely by fan voting, enhances the program's fairness, and makes the entire scoring mechanism more reasonable and balanced.                                  
\subsection{Strategic Recommendations for Future Rule Design}

Based on the stochastic survival modeling and counterfactual simulations conducted in this study, we propose a hybrid governance model for future seasons. This model combines the percentage aggregation method with a mandatory two-stage jury selection mechanism. The rationale for this dual-layer architecture stems from the following analytical conclusions:

\subsubsection{Foundational Aggregation: Adopting the Percentage Aggregation Method}
We recommend retaining the \textbf{percentage aggregation method} (sum of score shares) as the foundational aggregation rule, rather than adopting a ranking method\cite{r3}.
\begin{itemize}
    \item \textbf{Mitigating Information Loss}: Ranking methods inherently discretize continuous performance data, leading to “ordinal information loss.” This approach weakens the quantification of fan support, resulting in equal ranking advantages for contestants securing 50% votes versus 20% votes when leading within their respective tiers.
\item \textbf{Incentivizing Engagement}: The percentage method establishes a linear mapping between fan engagement and survival probability. This “high beta coefficient” characteristic stimulates active audience participation—marginal increases in votes directly translate into survival advantages, fostering “underdog storylines” that drive viewership (e.g., Iman Shumpert in Season 30).
\end{itemize}

\subsubsection{Essential Correction Mechanism: Judges' Selection Privilege}
While the percentage method maximizes engagement, it induces high volatility. Therefore, we strongly advise against using this mechanism alone. The “Judge's Choice (Bottom Two Safe)” must be enforced as a non-negotiable “elite system circuit breaker.”
\begin{itemize}
    \item Filtering statistical outliers: Our simulation of the “Bobby Bones anomaly” (S27) shows that a pure fan-voting system could render technical skill nearly irrelevant to final rankings. The judge selection mechanism acts as a high-pass filter, effectively blocking contestants whose technical performance consistently falls below the threshold ($Z_{score} < -1.5$) from exploiting fan voting loopholes to advance to the finals.
    \item \textbf{Restoring Competitive Fairness}: Quantitative analysis indicates the two-stage mechanism reduces the probability of “low-skill/high-popularity” contestants winning by approximately 85\%. This mechanism ensures fan communities determine the pool of potential qualifiers while professional judges retain veto power to uphold dance standards.
\end{itemize}

\textbf{Final Conclusion}: The optimal strategy is not to choose between popularity and skill, but to manage them separately. The percentage rule should set an upper limit on contestant potential through popularity effects, while the judge selection mechanism establishes the minimum technical capability required to maintain eligibility.



%==================================================================
% TASK 3: Impact of Contestant and Partner Characteristics
%==================================================================

\section{Impact of Contestant and Partner Characteristics}

To identify the most influential pre-competition traits of celebrities and professional dancers on Dancing with the Stars outcomes, we supplement the original dataset with four external data dimensions:\textbf{physical attributes} (specifically Body Mass Index), aggregated and standardized weekly \textbf{social media engagement} across platforms including Twitter, Instagram, Facebook, and YouTube, weekly trends in \textbf{public attention} measured via Google Search Volume, and a quantified assessment of \textbf{prior dance experience}.

Based on the enhanced dataset, we build a \textbf{multi-level regression framework} to examine performance across two temporal scales (season-level and weekly) in three dependent variables: judges' scores, fan votes, and final placement. A \textbf{mixed-effects model} is further used to isolate the specific impact of professional dancers from that of the celebrities themselves.

%------------------------------------------------------------------
\subsection{Model Specification}

% 3.1.1 因变量定义
\subsubsection{Dependent Variables}

We consider three dependent variables capturing different dimensions of ``success'' . The first outcome,  $Y_1$ (\texttt{avg\_judge\_score}), measures professional evaluation and is defined as the average judges’ score received by a contestant. 
The second outcome, $Y_2$ (\texttt{avg\_fan\_vote\_share}), reflects audience 
preference and is operationalized as the contestant’s average share of fan votes,  ranging from 0 to 1. The third outcome, $Y_3$ (\texttt{placement}), captures overall competitive success and is defined as the contestant’s final ranking in the season.

We use final placement rather than a weighted composite score as our measure of overall success because it avoids subjective weighting choices, remains comparable across seasons with different scoring regimes, and directly answers the question that, who ultimately wins the competition.

% 3.1.2 模型表达式
\subsubsection{Contestant-Level Model (Static Characteristics)}
We use a stratified modeling approach, beginning with static attributes (e.g. age, industry background, prior dance experience) that remain constant during a season\cite{r1}. Performance metrics are aggregated to season-level averages to reduce weekly noise. Three separate regressions are estimated for $Y_1, Y_2 and Y_3$ to distinguish judge, audience, and overall success mechanisms.

For contestant $i$:
\begin{equation}
Y_i = \beta_0 + \beta_1 \cdot \text{Age}_i + \beta_2 \cdot \text{isUS}_i 
    + \beta_3 \cdot \text{BMI}_i + \beta_4 \cdot \text{DanceExp}_i 
    + \sum_{k} \gamma_k \cdot \mathbf{1}[\text{Industry}_i = k] + \epsilon_i
\end{equation}

\subsubsection{Weekly-Level Model (Dynamic Characteristics)}
The second stratum addresses dynamic variability. While static traits set a contestant's baseline, their trajectory is often shaped by real-time public sentiment. We construct a panel data model with contestant-week observations ($N=2,777$) to capture the immediate impact of time-varying predictors: Social Media Popularity and Google Search Volume.

By controlling for static contestant characteristics (which act as quasi-fixed effects), this model specifically isolates the marginal effect of weekly buzz.

For contestant $i$ in week $t$:
\begin{equation}
Y_{it} = \alpha_0 + \alpha_1 \cdot \text{SocialMediaPop}_{it} 
       + \alpha_2 \cdot \text{GoogleSearch}_{it} + \mathbf{X}_i'\boldsymbol{\beta} 
       + \epsilon_{it}
\end{equation}

%------------------------------------------------------------------
\subsection{Results: Celebrity Characteristics}

% 3.2.1 模型拟合
\subsubsection{Model Fit}

\begin{table}[H]
\centering
\begin{tabular}{lccc}
\toprule
Model & $R^2$ & Adj. $R^2$ & $F$-statistic \\
\midrule
Judge Score (Contestant) & 0.232 & 0.211 & 11.20*** \\
Fan Vote (Contestant) & 0.154 & 0.131 & 6.75*** \\
Placement (Contestant) & 0.221 & 0.200 & 10.54*** \\
\midrule
Judge Score (Weekly) & 0.330 & 0.327 & 104.57*** \\
Fan Vote (Weekly) & 0.319 & 0.316 & 99.48*** \\
\bottomrule
\end{tabular}
\caption{Model fit statistics. ***: $p < 0.001$}
\end{table}

The contestant-level $R^2$ of 0.18--0.24 is consistent 
with behavioral research norms, indicating that pre-competition characteristics explain a meaningful but limited portion of variance---leaving room for actual 
dance performance to determine outcomes.

% 3.2.2 关键发现
\subsubsection{Significant Determinants of Performance}
Table \ref{tab:coefficients} summarizes the regression results for the static characteristics. The analysis reveals three distinct mechanisms driving competition outcomes:

\begin{table}[H]
\centering
\begin{tabular}{lccccccl}
\toprule
Variable & Judge $\beta$ & $p$ & Fan $\beta$ & $p$ & Place $\beta$ & $p$  \\
\midrule
Age & $-0.166$ & *** & $-0.001$ & *** & $+0.123$ & ***  \\
Dance Experience & $-0.169$ & & $+0.000$ & & $+0.176$ & *  \\
Industry: Social Media & $+5.61$ & *** & $-0.020$ & & $+0.04$ &  \\
Industry: Model & $-2.69$ & * & $-0.022$ & & $+2.76$ & ***  \\
\bottomrule
\end{tabular}
\caption{Selected regression coefficients. *: $p<0.1$, **: $p<0.05$, ***: $p<0.01$}
\label{tab:coefficients}
\end{table}

\textbf{The Age Advantage in Professional Assessment.} 
A strong negative correlation exists between contestant age and judge scores ($\beta = -0.166, p < 0.001$). Each additional decade of age corresponds to an average decrease of approximately 1.7 points, reflecting the premium placed on the physical agility and stamina associated with youth in ballroom dancing.

\textbf{The Divergence of Fame and Skill.} 
A critical finding emerges from the weekly model: \textbf{social media popularity} strongly predicts fan votes ($\beta = 0.014, p < 0.001$), where a one standard deviation increase in weekly social media buzz corresponds to a 1.4 percentage point gain in fan vote share. Judges also respond positively to social media presence, though to a lesser extent. The key distinction is that fan voting appears more directly driven by real-time publicity momentum.

\textbf{The "Social Media" Industry Effect.}
Contestants categorized as "Social Media Personalities" demonstrate a massive outlier effect in judge scores ($\beta = +5.61, p < 0.01$). This likely stems from a selection bias: social media stars cast on the show are often younger and possess dance-adjacent skills , giving them a baseline technical advantage over traditional actors or musicians.

%------------------------------------------------------------------
\subsection{Judge vs. Fan: What Do They Value?}


\begin{table}[H]
\centering
\begin{tabular}{lccc}
\toprule
Factor & Judge ($t$-stat) & Fan ($t$-stat) & Who cares more? \\
\midrule
Age & $-9.18$*** & $-7.69$*** & \textbf{Judges} \\
Social Media Popularity & $+2.82$* & $+30.97$*** & \textbf{Fans}  \\
Dance Experience & $-1.20$ & $+0.01$ & Neither \\
BMI & $+0.29$ & $-0.03$ & Neither \\
is\_US & $-0.37$ & $-0.82$ & Neither \\
\bottomrule
\end{tabular}
\caption{Comparison of $t$-statistics across Judge and Fan models}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{figures/task3_2_judge_fan_sensitivity.png}
    \caption{Sensitivity comparison between judges and fans. }
    \label{fig:judge_fan_sensitivity}
\end{figure}


A central question is whether judges and fans evaluate contestants 
using the same criteria. We compare $t$-statistics across models.

A clear dichotomy emerges: \textbf{Judges} emphasize physical and technical factors like age, dance experience, while \textbf{Fans} respond strongly to pre-existing popularity and social media presence.

%------------------------------------------------------------------
\subsection{Professional Dancer Effect}
To measure the influence of professional dance partners, we employ a  \textbf{Linear Mixed-Effects Model (LMM)} This approach, treating dancers as random effects, is preferred over including them as fixed covariates for two key reasons: it avoids consuming excessive degrees of freedom (given over 50 unique dancers across seasons), and it allows us to estimate the global variance($\sigma^2_u$) ttributable to the "partner factor" itself. The Intraclass Correlation Coefficient (ICC) is then calculated to determine the proportion of total success variance explained by partner assignment.

\subsubsection{Mixed-Effects Model Specification}

For contestant $i$ paired with professional dancer $j$:
\begin{equation}
Y_{ij} = \mathbf{X}_{ij}'\boldsymbol{\beta} + u_j + \epsilon_{ij}, 
\quad u_j \sim N(0, \sigma^2_u), \quad \epsilon_{ij} \sim N(0, \sigma^2_\epsilon)
\end{equation}

where $u_j$ is the random effect for dancer $j$, capturing the dancer's 
``added value'' beyond contestant characteristics. The key metric is the 
\textbf{ICC}, represents the proportion of outcome variance attributable to the professional dancer assignment.
\begin{equation}
\text{ICC} = \frac{\sigma^2_u}{\sigma^2_u + \sigma^2_\epsilon}
\end{equation}


\subsubsection{ICC Results}

\begin{table}[H]
\centering
\begin{tabular}{lcl}
\toprule
Dependent Variable & ICC & Interpretation \\
\midrule
Judge Score & \textbf{13.6\%} & Dancer explains $\sim$14\% of judge score variance \\
Fan Vote Share & \textbf{13.9\%} & Dancer matters similarly for audience votes \\
Placement & \textbf{22.8\%} & Dancer assignment most strongly affects final ranking \\
\bottomrule
\end{tabular}
\caption{Intraclass Correlation Coefficients for professional dancers}
\end{table}

Being assigned to a top-tier professional dancer 
provides a substantial advantage. The ICC of 22.8\% for placement means 
that nearly one-quarter of the variation in final ranking can be attributed 
to which dancer a celebrity is paired with---a factor entirely outside 
the contestant's control.

\subsubsection{Top Professional Dancers}

We rank dancers by the average placement of their partners 
(lower is better). Figure~\ref{fig:partner_ranking} presents the most successful professional dancers in DWTS history.

% \begin{table}[H]
% \centering
% \caption{Top 10 Professional Dancers by Partner Performance}
% \label{tab:top_dancers}
% \begin{tabular}{clcccc}
% \toprule
% \textbf{Rank} & \textbf{Dancer} & \textbf{Avg Placement} & \textbf{Partners} & \textbf{Best} & \textbf{Avg Judge} \\
% \midrule
% 1 & Derek Hough & 2.94 & 17 & 1 & 28.7 \\
% 2 & Julianne Hough & 4.20 & 5 & 1 & 23.6 \\
% 3 & Daniella Karagach & 4.60 & 5 & 1 & 27.6 \\
% 4 & Mark Ballas & 5.19 & 21 & 1 & 27.1 \\
% 5 & Valentin Chmerkovskiy & 5.26 & 19 & 1 & 28.7 \\
% 6 & Lindsay Arnold & 5.40 & 10 & 1 & 25.6 \\
% 7 & Witney Carson & 5.50 & 14 & 1 & 28.1 \\
% 8 & Cheryl Burke & 5.80 & 25 & 1 & 24.3 \\
% 9 & Maksim Chmerkovskiy & 6.00 & 17 & 1 & 25.1 \\
% 10 & Sasha Farber & 6.08 & 12 & 3 & 28.0 \\
% \bottomrule
% \end{tabular}
% \end{table}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.88\textwidth]{figures/task3_2_partner_ranking_top10_dual.png}
    \caption{Top 10 professional dancers ranked by average partner placement. The annotation $n$ indicates the number of celebrity partners each dancer has trained.}
    \label{fig:partner_ranking}
\end{figure}

Several notable patterns emerge from the data. \textbf{Derek Hough }clearly dominates in terms of professional success: across 17 partners, his average partner placement is 2.94, implying that his partners finish in the top three on average, making him statistically the most successful professional dancer on the show. However, we also found that while the first-place partner did indeed have the highest average judges' score, these scores did not necessarily indicate the partner's overall average score. Julianne Hough, who ranked second, only received an average judges' score of 23.6. Meanwhile, Valentin Chmerkovskiy, who had the same average score as Derek at 28.7, only ranked fifth among the partners, with an average placement of 5.26. This suggests that \textbf{audience preferences} are \textbf{not} significantly influenced by the dance partners.


% ----------------------------------------------------------------------
% TASK 4: Optimization of Competition Mechanism
% ----------------------------------------------------------------------

% =========================================================
% TASK 4: OPTIMIZATION OF COMPETITION MECHANISM
% =========================================================

% =========================================================
% TASK 4: OPTIMIZATION VIA DYNAMIC WEIGHTING SYSTEM
% =========================================================

\section{Optimization of Competition Mechanism: From Static Equilibrium to Dynamic Control}

This section addresses the core challenge of balancing professional integrity with market-driven success. We propose a \textbf{Dynamic Weighting System} that optimizes the judge-weight parameter $\vec{\lambda}(t)$ on a weekly basis. Unlike traditional fixed rules, this approach treats the competition as a discrete-time control system, aiming to maximize the comprehensive benefit through three stages of model evolution.

\subsection{Objective Function}

We define the global objective function $J$ as a multi-objective optimization problem. To quantify the commercial dimension, we introduce the \textbf{Commercial Value Index (CCVI)}, which is explicitly constructed using a \textbf{PID (Proportional-Integral-Derivative)} framework:
\begin{equation}
    \max_{\vec{\lambda}} J(\vec{\lambda}) = 0.3 \tilde{f}_{CCVI} + 0.4 \tilde{f}_{Fair} + 0.2 \tilde{f}_{Satis} + 0.1 \tilde{f}_{Celeb}
\end{equation}

\noindent \textbf{Mathematical Definition of PID Components in CCVI:} 
The commercial impact of the show is modeled as a dynamic signal response, where the optimal $\vec{\lambda}$ must balance three distinct commercial forces:
\begin{itemize}
    \item \textbf{Proportional Gain ($P$):} Represents the \textbf{Peak Search Volume}. $P$ dictates the show's instantaneous premium pricing power for high-stakes advertising slots.
    \item \textbf{Integral Gain ($I$):} Represents the \textbf{Cumulative Traffic Volume} ($I = \int \text{Traffic } dt$). $I$ measures audience stickiness and long-term brand loyalty, essential for streaming subscriber retention.
    \item \textbf{Derivative Gain ($D$):} Represents the \textbf{Viral Growth Rate}. $D$ captures the "hype" velocity and social media ROI, indicating the efficiency of marketing investments.
\end{itemize}

\noindent \textbf{Renormalization and Fairness:} To maintain competitive integrity, we minimize $f_{Fair}$ (the discrepancy between fan and judge shares) and utilize \textbf{Dynamic Renormalization} to ensure that as contestants are eliminated, the vote shares of survivors are recalibrated to sum to unity, preventing "denominator drift" in our counterfactual simulations.

\subsection{Evolution of Optimization: Three-Stage Performance Gains}

The model evolved through three iterations of increasing granular control. \textbf{Stage I (Static Baseline)} assumes $\lambda \equiv 0.5$ for all seasons, representing the status quo. \textbf{Stage II (Season-level Optimization)} allows each season to find its unique optimal fixed weight $\lambda_s$, while \textbf{Stage III (Weekly Dynamic Control)} optimizes a control vector $\vec{\lambda} = [\lambda_1, \dots, \lambda_T]$. 

As evidenced in Table \ref{tab:benefit_evolution}, the progression from Stage I to Stage III yields substantial improvements. In Season 25 (a "Recession Era" case), the total benefit rises from a baseline of 0.25 to 0.36, a \textbf{43\% improvement}. This demonstrates that while fixed rules suffice for stable seasons, dynamic intervention is mandatory for crisis management.

\begin{table}[htbp]
    \centering
    \caption{Total Benefit ($J$) Evolution Across Three Optimization Stages}
    \label{tab:benefit_evolution}
    \begin{tabular}{lcccc}
        \toprule
        \textbf{Season} & \textbf{Stage I (Baseline)} & \textbf{Stage II (Fixed Opt)} & \textbf{Stage III (Dynamic Opt)} & \textbf{Total Gain} \\
        \midrule
        \textbf{S5: Golden}   & 0.489 & 0.532 ($\lambda=0.4$) & \textbf{0.579} & +18.4\% \\
        \textbf{S8: Volatile} & 0.371 & 0.429 ($\lambda=0.2$) & \textbf{0.463} & +24.6\% \\
        \textbf{S25: Crisis}  & 0.252 & 0.365 ($\lambda=0.3$) & \textbf{0.361} & \textbf{+43.5\%} \\
        \bottomrule
    \end{tabular}
\end{table}

\subsection{Strategic Insights from the Optimal Dynamic Control Method}

Figure \ref{fig:comprehensive_plots} visualizes the results. Subplot (A) highlights the benefit gap between static and dynamic strategies. Subplot (B) reveals the underlying logic of the optimized dynamic weight for Season 25, showing a distinct **"N-Shape" curve**.

\begin{figure}[htbp]
    \centering
    % \includegraphics[width=1.0\textwidth]{task4_final_comparison_new.png}
    \fbox{\begin{minipage}{1.0\textwidth}
        \centering \vspace{1cm}
        [Subfigure A: Bar chart showing Baseline vs Fixed vs Dynamic benefits per season] \\
        [Subfigure B: Line chart of Lambda Trajectory for S25 (Red Line) and S5 (Light Blue)] \\
        \vspace{1cm}
    \end{minipage}}
    \caption{\textbf{Comprehensive Optimization Analysis.} (A) Demonstrates the incremental benefit gains through model iterations. (B) Reveals the adaptive "N-Shape" strategy for S25: early-season traffic accumulation, mid-season technical screening, and a professional finale guardrail.}
    \label{fig:comprehensive_plots}
\end{figure}

The "N-Shape" strategy avoids the compromise of a fixed $\lambda$. In the \textbf{Traffic Accumulation Phase} (Weeks 1-4, $\lambda \approx 0.35$), the system lowers the judge's influence to allow high-profile celebrities to maximize the PID-P (Peak) component. This is followed by a \textbf{Technical Screening Phase} (Week 5, $\lambda = 0.69$), where a sharp spike in professional control eliminates "low-skill, high-popularity" outliers, effectively resetting the Fairness metric. After an \textbf{Audience Activation Phase} (Week 9), the season concludes with a \textbf{Professional Guardrail} (Week 10, $\lambda = 0.79$), where the judges ensure the final champion meets the brand's professional standards, protecting the show's long-term credit. 

In summary, Task 4 proves that commercial peak and competitive fairness can be harmonized through temporal separation of power, provided the weighting system is dynamically calibrated to the specific signal of each season.


\section{Model Analysis}
\subsection{Strength}
\begin{itemize}
\item[ \ding{52} ]
\item[ \ding{52} ]
\end{itemize}

\bibliographystyle{unsrt}
\bibliography{ref}  



\begin{appendices}


\end{appendices}


\AImatter

\begin{ReportAiUse}{1}
\bibitem{AI1}
GitHub Copilot (Agent Mode)\\
Query: Develop convex optimization model for DWTS fan vote estimation\\
Output: Used to assist with model formulation, code debugging, and LaTeX formatting for the inverse fan vote estimation problem.
\end{ReportAiUse}

\end{document}
